{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse or Human? In-graph training loop Assignment\n",
    "\n",
    "This assignment lets you practice how to train a Keras model on the [horses_or_humans](https://www.tensorflow.org/datasets/catalog/horses_or_humans) dataset with the entire training process performed in graph mode.  These steps include:\n",
    "- loading batches\n",
    "- calculating gradients\n",
    "- updating parameters\n",
    "- calculating validation accuracy\n",
    "- repeating the loop until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4EKOpw9mObL"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Import TensorFlow 2.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9oECvVSI1Kj"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mT7meGqrZTz9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 17:44:06.003407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Em5dzSUOtLRP"
   },
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "Load the horses to human dataset, splitting 80% for the training set and 20% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 17:44:11.196635: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 153.59 MiB (download: 153.59 MiB, generated: Unknown size, total: 153.59 MiB) to ./data/horses_or_humans/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560419a60e8e457a9b70771671cf7a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7073c7fe841f43809f33b99fe52e58b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/1027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling data/horses_or_humans/3.0.0.incompleteOO4KTF/horses_or_humans-train.tfrecord*...:   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling data/horses_or_humans/3.0.0.incompleteOO4KTF/horses_or_humans-test.tfrecord*...:   0%|          | 0/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset horses_or_humans downloaded and prepared to ./data/horses_or_humans/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "splits, info = tfds.load('horses_or_humans', as_supervised=True, with_info=True, split=['train[:80%]', 'train[80%:]', 'test'], data_dir='./data')\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJdruxxGhBi5"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process an image (please complete this section)\n",
    "\n",
    "You'll define a mapping function that resizes the image to a height of 224 by 224, and normalizes the pixels to the range of 0 to 1.  Note that pixels range from 0 to 255.\n",
    "\n",
    "- You'll use the following function: [tf.image.resize](https://www.tensorflow.org/api_docs/python/tf/image/resize) and pass in the (height,width) as a tuple (or list).\n",
    "- To normalize, divide by a floating value so that the pixel range changes from [0,255] to [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpQi4Jo9cFq0"
   },
   "outputs": [],
   "source": [
    "# Create a autograph pre-processing function to resize and normalize an image\n",
    " \n",
    "@tf.function\n",
    "def map_fn(img, label):\n",
    "    image_height = 224\n",
    "    image_width = 224\n",
    " \n",
    "    # resize the image\n",
    "    img = tf.image.resize(images=img, size=(image_height,image_width))\n",
    "    \n",
    "    # normalize the image\n",
    "    img /= .255\n",
    " \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "## TEST CODE:\n",
    "\n",
    "test_image, test_label = list(train_examples)[0]\n",
    "\n",
    "test_result = map_fn(test_image, test_label)\n",
    "\n",
    "print(test_result[0].shape)\n",
    "print(test_result[1].shape)\n",
    "\n",
    "del test_image, test_label, test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "(224, 224, 3)\n",
    "()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply pre-processing to the datasets (please complete this section)\n",
    "\n",
    "Apply the following steps to the training_examples:\n",
    "- Apply the `map_fn` to the training_examples\n",
    "- Shuffle the training data using `.shuffle(buffer_size=)` and set the buffer size to the number of examples.\n",
    "- Group these into batches using `.batch()` and set the batch size given by the parameter.\n",
    "\n",
    "Hint: You can look at how validation_examples and test_examples are pre-processed to get a sense of how to chain together multiple function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sv5bEYhaeUUO"
   },
   "outputs": [],
   "source": [
    "# Prepare train dataset by using preprocessing with map_fn, shuffling and batching\n",
    "def prepare_dataset(train_examples, validation_examples, test_examples, num_examples, map_fn, batch_size):\n",
    " \n",
    "    train_ds = train_examples.map(map_fn).shuffle(buffer_size=len(train_examples)).batch(batch_size)\n",
    " \n",
    "    valid_ds = validation_examples.map(map_fn).batch(batch_size)\n",
    "    test_ds = test_examples.map(map_fn).batch(batch_size)\n",
    "    \n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = prepare_dataset(train_examples, validation_examples, test_examples, num_examples, map_fn, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 17:50:50.031764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-14 17:50:50.032916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [2]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "## TEST CODE:\n",
    "\n",
    "test_train_ds = list(train_ds)\n",
    "print(len(test_train_ds))\n",
    "print(test_train_ds[0][0].shape)\n",
    "\n",
    "del test_train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "26\n",
    "(32, 224, 224, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znmy4l8ntMvW"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ltxyJVWTqNAO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23561152  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,565,250\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,561,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODULE_HANDLE = 'https://tfhub.dev/tensorflow/resnet_50/feature_vector/1'\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(MODULE_HANDLE, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ikb79EzkjpPk"
   },
   "source": [
    "## Define optimizer: (please complete these sections)\n",
    "Define the [Adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) that is in the tf.keras.optimizers module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_adam_optimizer():\n",
    " \n",
    "    # Define the adam optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    " \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.optimizers.adam.Adam'>\n"
     ]
    }
   ],
   "source": [
    "## TEST CODE:\n",
    "\n",
    "test_optimizer = set_adam_optimizer()\n",
    "\n",
    "print(type(test_optimizer))\n",
    "\n",
    "del test_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "<class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function (please complete this section)\n",
    "\n",
    "Define the loss function as the [sparse categorical cross entropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) that's in the tf.keras.losses module.  Use the same function for both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sparse_cat_crossentropy_loss():\n",
    " \n",
    "    # Define object oriented metric of Sparse categorical crossentropy for train and val loss\n",
    "    train_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    val_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    " \n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.losses.SparseCategoricalCrossentropy'>\n",
      "<class 'keras.losses.SparseCategoricalCrossentropy'>\n"
     ]
    }
   ],
   "source": [
    "## TEST CODE:\n",
    "\n",
    "test_train_loss, test_val_loss = set_sparse_cat_crossentropy_loss()\n",
    "\n",
    "print(type(test_train_loss))\n",
    "print(type(test_val_loss))\n",
    "\n",
    "del test_train_loss, test_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "<class 'tensorflow.python.keras.losses.SparseCategoricalCrossentropy'>\n",
    "<class 'tensorflow.python.keras.losses.SparseCategoricalCrossentropy'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the acccuracy function (please complete this section)\n",
    "Define the accuracy function as the [spare categorical accuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy) that's contained in the tf.keras.metrics module.   Use the same function for both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sparse_cat_crossentropy_accuracy():\n",
    " \n",
    "    # Define object oriented metric of Sparse categorical accuracy for train and val accuracy\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='sparse_categorical_accuracy', dtype=None\n",
    ")\n",
    "\n",
    "    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='sparse_categorical_accuracy', dtype=None\n",
    ")\n",
    " \n",
    "    return train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.metrics.accuracy_metrics.SparseCategoricalAccuracy'>\n",
      "<class 'keras.metrics.accuracy_metrics.SparseCategoricalAccuracy'>\n"
     ]
    }
   ],
   "source": [
    "## TEST CODE:\n",
    "\n",
    "test_train_accuracy, test_val_accuracy = set_sparse_cat_crossentropy_accuracy()\n",
    "\n",
    "print(type(test_train_accuracy))\n",
    "print(type(test_val_accuracy))\n",
    "\n",
    "del test_train_accuracy, test_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "<class 'tensorflow.python.keras.metrics.SparseCategoricalAccuracy'>\n",
    "<class 'tensorflow.python.keras.metrics.SparseCategoricalAccuracy'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the three functions that you defined to set the optimizer, loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j92oDYGCjnBh"
   },
   "outputs": [],
   "source": [
    "optimizer = set_adam_optimizer()\n",
    "train_loss, val_loss = set_sparse_cat_crossentropy_loss()\n",
    "train_accuracy, val_accuracy = set_sparse_cat_crossentropy_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeYV6mKnJGMr"
   },
   "source": [
    "### Define the training loop (please complete this section)\n",
    "\n",
    "In the training loop:\n",
    "- Get the model predictions: use the model, passing in the input `x`\n",
    "- Get the training loss: Call `train_loss`, passing in the true `y` and the predicted `y`.\n",
    "- Calculate the gradient of the loss with respect to the model's variables: use `tape.gradient` and pass in the loss and the model's `trainable_variables`.\n",
    "- Optimize the model variables using the gradients: call `optimizer.apply_gradients` and pass in a `zip()` of the two lists: the gradients and the model's `trainable_variables`.\n",
    "- Calculate accuracy: Call `train_accuracy`, passing in the true `y` and the predicted `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xtg_MMhJETd"
   },
   "outputs": [],
   "source": [
    "# this code uses the GPU if available, otherwise uses a CPU\n",
    "device = '/gpu:0' if tf.config.list_physical_devices('GPU') else '/cpu:0'\n",
    "EPOCHS = 2\n",
    "\n",
    "# Custom training step\n",
    "def train_one_step(model, optimizer, x, y, train_loss, train_accuracy):\n",
    "    '''\n",
    "    Trains on a batch of images for one step.\n",
    "    \n",
    "    Args:\n",
    "        model (keras Model) -- image classifier\n",
    "        optimizer (keras Optimizer) -- optimizer to use during training\n",
    "        x (Tensor) -- training images\n",
    "        y (Tensor) -- training labels\n",
    "        train_loss (keras Loss) -- loss object for training\n",
    "        train_accuracy (keras Metric) -- accuracy metric for training\n",
    "    '''\n",
    "    with tf.GradientTape() as tape:\n",
    " \n",
    "        # Run the model on input x to get predictions\n",
    "        predictions = model(x)\n",
    "        \n",
    "        # Compute the training loss using `train_loss`, passing in the true y and the predicted y\n",
    "        loss = train_loss(y_true=y, y_pred=predictions)\n",
    "\n",
    "    # Using the tape and loss, compute the gradients on model variables using tape.gradient\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    \n",
    "    # Zip the gradients and model variables, and then apply the result on the optimizer\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    # Call the train accuracy object on ground truth and predictions\n",
    "    train_accuracy.update_state(y, predictions)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.6931472, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## TEST CODE:\n",
    "\n",
    "def base_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(2))\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "test_model = base_model()\n",
    "\n",
    "test_optimizer = set_adam_optimizer()\n",
    "test_image = tf.ones((2,2))\n",
    "test_label = tf.ones((1,))\n",
    "test_train_loss, _ = set_sparse_cat_crossentropy_loss()\n",
    "test_train_accuracy, _ = set_sparse_cat_crossentropy_accuracy()\n",
    "\n",
    "test_result = train_one_step(test_model, test_optimizer, test_image, test_label, test_train_loss, test_train_accuracy)\n",
    "print(test_result)\n",
    "\n",
    "del test_result, test_model, test_optimizer, test_image, test_label, test_train_loss, test_train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "You will see a Tensor with the same shape and dtype. The value might be different.\n",
    "\n",
    "```\n",
    "tf.Tensor(0.6931472, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the 'train' function (please complete this section)\n",
    "\n",
    "You'll first loop through the training batches to train the model. (Please complete these sections)\n",
    "- The `train` function will use a for loop to iteratively call the `train_one_step` function that you just defined.\n",
    "- You'll use `tf.print` to print the step number, loss, and train_accuracy.result() at each step.  Remember to use tf.print when you plan to generate autograph code.\n",
    "\n",
    "Next, you'll loop through the batches of the validation set to calculation the validation loss and validation accuracy. (This code is provided for you).  At each iteration of the loop:\n",
    "- Use the model to predict on x, where x is the input from the validation set.\n",
    "- Use val_loss to calculate the validation loss between the true validation 'y' and predicted y.\n",
    "- Use val_accuracy to calculate the accuracy of the predicted y compared to the true y.\n",
    "\n",
    "Finally, you'll print the validation loss and accuracy using tf.print. (Please complete this section)\n",
    "- print the final `loss`, which is the validation loss calculated by the last loop through the validation dataset.\n",
    "- Also print the val_accuracy.result().\n",
    "\n",
    "**HINT**\n",
    "If you submit your assignment and see this error for your stderr output: \n",
    "```\n",
    "Cannot convert 1e-07 to EagerTensor of dtype int64\n",
    "```\n",
    "Please check your calls to train_accuracy and val_accuracy to make sure that you pass in the true and predicted values in the correct order (check the documentation to verify the order of parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorate this function with tf.function to enable autograph on the training loop\n",
    "@tf.function\n",
    "def train(model, optimizer, epochs, device, train_ds, train_loss, train_accuracy, valid_ds, val_loss, val_accuracy):\n",
    "    '''\n",
    "    Performs the entire training loop. Prints the loss and accuracy per step and epoch.\n",
    "    \n",
    "    Args:\n",
    "        model (keras Model) -- image classifier\n",
    "        optimizer (keras Optimizer) -- optimizer to use during training\n",
    "        epochs (int) -- number of epochs\n",
    "        train_ds (tf Dataset) -- the train set containing image-label pairs\n",
    "        train_loss (keras Loss) -- loss function for training\n",
    "        train_accuracy (keras Metric) -- accuracy metric for training\n",
    "        valid_ds (Tensor) -- the val set containing image-label pairs\n",
    "        val_loss (keras Loss) -- loss object for validation\n",
    "        val_accuracy (keras Metric) -- accuracy metric for validation\n",
    "    '''\n",
    "    step = 0\n",
    "    loss = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_ds:\n",
    "            # training step number increments at each iteration\n",
    "            step += 1\n",
    "            with tf.device(device_name=device):\n",
    " \n",
    "                # Run one training step by passing appropriate model parameters\n",
    "                # required by the function and finally get the loss to report the results\n",
    "                loss = train_one_step(model, optimizer, x, y, train_loss, train_accuracy)\n",
    " \n",
    "            # Use tf.print to report your results.\n",
    "            # Print the training step number, loss and accuracy\n",
    "            tf.print('Step', step, \n",
    "                   ': train loss', loss, \n",
    "                   '; train accuracy', train_accuracy.result())\n",
    "\n",
    "        with tf.device(device_name=device):\n",
    "            for x, y in valid_ds:\n",
    "                # Call the model on the batches of inputs x and get the predictions\n",
    "                y_pred = model(x)\n",
    "                loss = val_loss(y, y_pred)\n",
    "                val_accuracy(y, y_pred)\n",
    "        \n",
    "        # Print the validation loss and accuracy\n",
    " \n",
    "        tf.print('Validation loss', loss,\n",
    "                 '; Validation accuracy', val_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `train` function to train your model! You should see the loss generally decreasing and the accuracy increasing.\n",
    "\n",
    "**Note**: **Please let the training finish before submitting** and **do not** modify the next cell. It is required for grading. This will take around 5 minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "graded": true,
    "id": "6iDWgg977wb9",
    "name": "train"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:10:54.907541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_181' with dtype resource\n",
      "\t [[{{node Placeholder/_181}}]]\n",
      "2023-07-14 18:10:54.915319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_41' with dtype resource\n",
      "\t [[{{node Placeholder/_41}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 : train loss 306.738434 ; train accuracy 0.53997612\n",
      "Step 2 : train loss 383.626709 ; train accuracy 0.540983617\n",
      "Step 3 : train loss 310.264099 ; train accuracy 0.54482758\n",
      "Step 4 : train loss 511.965576 ; train accuracy 0.54571104\n",
      "Step 5 : train loss 104.087845 ; train accuracy 0.55044347\n",
      "Step 6 : train loss 554.876709 ; train accuracy 0.55010891\n",
      "Step 7 : train loss 431.286774 ; train accuracy 0.549250543\n",
      "Step 8 : train loss 228.3125 ; train accuracy 0.551578939\n",
      "Step 9 : train loss 488.007446 ; train accuracy 0.552795053\n",
      "Step 10 : train loss 655.157715 ; train accuracy 0.552444\n",
      "Step 11 : train loss 119.806915 ; train accuracy 0.556613207\n",
      "Step 12 : train loss 482.112701 ; train accuracy 0.557692289\n",
      "Step 13 : train loss 760.548645 ; train accuracy 0.556310654\n",
      "Step 14 : train loss 207.105469 ; train accuracy 0.557839394\n",
      "Step 15 : train loss 466.084106 ; train accuracy 0.557909608\n",
      "Step 16 : train loss 647.571 ; train accuracy 0.557977736\n",
      "Step 17 : train loss 176.700073 ; train accuracy 0.559415\n",
      "Step 18 : train loss 381.146912 ; train accuracy 0.560360372\n",
      "Step 19 : train loss 634.942444 ; train accuracy 0.558170497\n",
      "Step 20 : train loss 152.335114 ; train accuracy 0.560420334\n",
      "Step 21 : train loss 580.571228 ; train accuracy 0.560449064\n",
      "Step 22 : train loss 500.225281 ; train accuracy 0.562180579\n",
      "Step 23 : train loss 402.932983 ; train accuracy 0.560924351\n",
      "Step 24 : train loss 627.163574 ; train accuracy 0.559286892\n",
      "Step 25 : train loss 522.422 ; train accuracy 0.559329\n",
      "Step 26 : train loss 396.538544 ; train accuracy 0.560016215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:13:11.901269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_162' with dtype resource\n",
      "\t [[{{node Placeholder/_162}}]]\n",
      "2023-07-14 18:13:11.911322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_157' with dtype resource\n",
      "\t [[{{node Placeholder/_157}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 606.782104 ; Validation accuracy 0.606504083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:13:54.041032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_106' with dtype resource\n",
      "\t [[{{node Placeholder/_106}}]]\n",
      "2023-07-14 18:13:54.050795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_162' with dtype resource\n",
      "\t [[{{node Placeholder/_162}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27 : train loss 232.49765 ; train accuracy 0.561649323\n",
      "Step 28 : train loss 245.584625 ; train accuracy 0.564031601\n",
      "Step 29 : train loss 304.66214 ; train accuracy 0.56479311\n",
      "Step 30 : train loss 228.68866 ; train accuracy 0.565921366\n",
      "Step 31 : train loss 218.507141 ; train accuracy 0.566260457\n",
      "Step 32 : train loss 241.437485 ; train accuracy 0.566215217\n",
      "Step 33 : train loss 264.014771 ; train accuracy 0.568401515\n",
      "Step 34 : train loss 512.747 ; train accuracy 0.568699479\n",
      "Step 35 : train loss 300.156616 ; train accuracy 0.56935364\n",
      "Step 36 : train loss 77.4740601 ; train accuracy 0.572864294\n",
      "Step 37 : train loss 390.918304 ; train accuracy 0.573456347\n",
      "Step 38 : train loss 140.512665 ; train accuracy 0.575789452\n",
      "Step 39 : train loss 133.195404 ; train accuracy 0.578764737\n",
      "Step 40 : train loss 293.548706 ; train accuracy 0.580302\n",
      "Step 41 : train loss 222.289246 ; train accuracy 0.581126928\n",
      "Step 42 : train loss 126.338379 ; train accuracy 0.582269967\n",
      "Step 43 : train loss 32.458004 ; train accuracy 0.586046517\n",
      "Step 44 : train loss 312.517395 ; train accuracy 0.5857988\n",
      "Step 45 : train loss 224.676895 ; train accuracy 0.586857498\n",
      "Step 46 : train loss 282.093 ; train accuracy 0.587572455\n",
      "Step 47 : train loss 273.605713 ; train accuracy 0.588910162\n",
      "Step 48 : train loss 77.9547424 ; train accuracy 0.590851724\n",
      "Step 49 : train loss 330.463623 ; train accuracy 0.590880692\n",
      "Step 50 : train loss 289.482544 ; train accuracy 0.592455149\n",
      "Step 51 : train loss 570.849792 ; train accuracy 0.59063077\n",
      "Step 52 : train loss 270.473236 ; train accuracy 0.591849148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:16:05.972342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_59' with dtype resource\n",
      "\t [[{{node Placeholder/_59}}]]\n",
      "2023-07-14 18:16:05.980183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_270' with dtype resource\n",
      "\t [[{{node Placeholder/_270}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 590.922546 ; Validation accuracy 0.593902469\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, EPOCHS, device, train_ds, train_loss, train_accuracy, valid_ds, val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8m3iJgx7SV1"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "You can now see how your model performs on test images. First, let's load the test dataset and generate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwFx4Nbh25p5"
   },
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "test_labels = []\n",
    "\n",
    "predictions = []\n",
    "with tf.device(device_name=device):\n",
    "    for images, labels in test_ds:\n",
    "        preds = model(images)\n",
    "        preds = preds.numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "        test_imgs.extend(images.numpy())\n",
    "        test_labels.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a utility function for plotting an image and its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "IiutdErSpRH_"
   },
   "outputs": [],
   "source": [
    "# Utilities for plotting\n",
    "\n",
    "class_names = ['horse', 'human']\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    img = np.squeeze(img)\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    # green-colored annotations will mark correct predictions. red otherwise.\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    # print the true label first\n",
    "    print(true_label)\n",
    "  \n",
    "    # show the image and overlay the prediction\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the result of a single image\n",
    "\n",
    "Choose an index and display the model's prediction for that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "aVknjW4A11uz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the outputs \n",
    "\n",
    "# you can modify the index value here from 0 to 255 to test different images\n",
    "index = 8 \n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(index, predictions, test_labels, test_imgs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "TF3C2W3-1",
    "TF3C2W3-2",
    "TF3C2W3-3",
    "TF3C2W3-4",
    "TF3C2W3-5",
    "TF3C2W3-6",
    "TF3C2W3-7"
   ]
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
