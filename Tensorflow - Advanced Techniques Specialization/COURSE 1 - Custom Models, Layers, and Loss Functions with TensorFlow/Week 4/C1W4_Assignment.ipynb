{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC7zSrbOWiz0"
   },
   "source": [
    "# Week 4 Assignment: Create a VGG network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYr0CvZmPY3L"
   },
   "source": [
    "In this exercise, you will build a class that implements a [VGG network](https://towardsdatascience.com/vgg-neural-networks-the-next-step-after-alexnet-3f91fa9ffe2c) and then train it to classify images of cats and dogs. The model will look something like this:\n",
    "\n",
    "<img src='https://github.com/y33-j3T/Coursera-Deep-Learning/blob/master/Custom%20Models%2C%20Layers%2C%20and%20Loss%20Functions%20with%20TensorFlow/Week%204%20-%20Custom%20Models/VGG.png?raw=1'>\n",
    "\n",
    "It is primarily made up of a series of Conv2D layers followed by a softmax activated layers to classify the image. As you can see, this will be a handful and the code will look huge if you specify each layer individually. As shown in the lectures, you can instead use model subclassing to build complex architectures. You can encapsulate repeating parts of a network then reuse that code when building the final model. You will get to practice that in this exercise. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z01I5nj0NAOu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7iOW0-4PY3N"
   },
   "source": [
    "## Create named-variables dynamically\n",
    "\n",
    "In this assignment, you will see the use of the Python function `vars()`.  This will allow you to use a for loop to define and set multiple variables with a similar name, such as var1, var2, var3.  \n",
    "\n",
    "Please go through the following examples to get familiar with `vars()`, as you will use it when building the VGG model.\n",
    "- You'll start by defining a class `MyClass`\n",
    "- It contains one variable `var1`.  \n",
    "- Create an object of type `MyClass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1iFvU1RwPY3N"
   },
   "outputs": [],
   "source": [
    "# Define a small class MyClass\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        # One class variable 'a' is set to 1\n",
    "        self.var1 = 1\n",
    "\n",
    "# Create an object of type MyClass()\n",
    "my_obj = MyClass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyIoHdnfPY3O"
   },
   "source": [
    "Python classes have an attribute called `__dict__`.\n",
    "- `__dict__` is a Python dictionary that contains the object's instance variables and values as key value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Gm3X82qVPY3O",
    "outputId": "ead95ec9-75d6-4c9c-9186-852cfd3aa6ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_obj.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed9d6UxUPY3P"
   },
   "source": [
    "If you call `vars()` and pass in an object, it will call the object's `__dict__` attribute, which is a Python dictionary containing the object's instance variables and their values as ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_t5wtb1CPY3Q",
    "outputId": "85530277-07fa-47bd-be4f-5f59bc570f5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2M5ACZhPY3Q"
   },
   "source": [
    "You may be familiar with adding new variable like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CnyztphGPY3R",
    "outputId": "1a75cf82-c370-4bb0-8d4f-475c2ba1c077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1, 'var2': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new instance variable and give it a value\n",
    "my_obj.var2 = 2\n",
    "\n",
    "# Calls vars() again to see the object's instance variables\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOs2ESkOPY3R"
   },
   "source": [
    "Here is another way that you can add an instance variable to an object, using `vars()`.\n",
    "- Retrieve the Python dictionary `__dict__` of the object using vars(my_obj).\n",
    "- Modify this `__dict__` dictionary using square bracket notation and passing in the variable's name as a string: `['var3'] = 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EEHMOeyCPY3R",
    "outputId": "11e166be-a6fe-4437-e3c3-53a5e515201e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1, 'var2': 2, 'var3': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call vars, passing in the object.  Then access the __dict__ dictionary using square brackets\n",
    "vars(my_obj)['var3'] = 3\n",
    "\n",
    "# Call vars() to see the object's instance variables\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5YPIk3jPY3S"
   },
   "source": [
    "#### Why this is helpful!\n",
    "You may be wondering why you would need another way to access an object's instance variables.  \n",
    "- Notice that when using `vars()`, you can now pass in the name of the variable `var3` as a string.\n",
    "- What if you plan to use several variables that are similarly named (`var4`, `var5` ... `var9`) and wanted a convenient way to access them by incrementing a number?\n",
    "\n",
    "Try this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ESrExtM8PY3S",
    "outputId": "a3b32833-abe9-4965-c49a-ad17d494e161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1,\n",
       " 'var2': 2,\n",
       " 'var3': 3,\n",
       " 'var4': 0,\n",
       " 'var5': 0,\n",
       " 'var6': 0,\n",
       " 'var7': 0,\n",
       " 'var8': 0,\n",
       " 'var9': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a for loop to increment the index 'i'\n",
    "for i in range(4,10):\n",
    "    # Format a string that is var\n",
    "    vars(my_obj)[f'var{i}'] = 0\n",
    "    \n",
    "# View the object's instance variables!\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmonfGMUPY3S"
   },
   "source": [
    "There are couple equivalent ways in Python to format a string.  Here are two of those ways:\n",
    "- f-string: f\"var{i}\"\n",
    "- .format: \"var{}\".format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ab_3Vak-PY3S",
    "outputId": "c13873e8-3cc6-48c2-ae9d-cfe54e0ff535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1\n",
      "var2\n"
     ]
    }
   ],
   "source": [
    "# Format a string using f-string notation\n",
    "i=1\n",
    "print(f\"var{i}\")\n",
    "\n",
    "# Format a string using .format notation\n",
    "i=2\n",
    "print(\"var{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-qbnGQ3PY3T"
   },
   "source": [
    "You can access the variables of a class inside the class definition using `vars(self)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DXbFrJzTPY3T",
    "outputId": "d8f95180-764d-4181-b3c8-6fa596bed43f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a small class MyClass\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        # Use vars(self) to access the class's dictionary of variables\n",
    "        vars(self)['var1'] = 1\n",
    "\n",
    "# Create an object of type MyClass()\n",
    "my_obj = MyClass()\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxjztJStPY3T"
   },
   "source": [
    "You'll see this in the upcoming code.  Now you'll start building the VGG network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1T1UMw5YAkp"
   },
   "source": [
    "## Create a generic VGG block (TODO)\n",
    "\n",
    "The VGG Network has blocks of layers, where each block has a varied number of layers.\n",
    "- In order to create blocks of layers that have a customizable number of conv2D layers, you'll define a class `Block`, which can generate a customizable block of layers \n",
    "\n",
    "\n",
    "### `__init__`\n",
    "In the constructor `__init__`, store the conv2D parameters and also define the number of conv2D layers using the parameters passed into `__init__`.\n",
    "- Store the filters, kernel_size, and repetitions as class variables so that they can be used later in the `call` function.\n",
    "- Using a for loop, define a number of Conv2D [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/) layers, based on the number of `repetitions` desired for this block.\n",
    "    - You can define each conv2D layer using `vars` and string formatting to create conv2D_0, conv2D_1, conv2D_3 etc.\n",
    "    - Set these four parameters of Conv2D:\n",
    "        - filters\n",
    "        - kernel_size\n",
    "        - activation: set this to 'relu'\n",
    "        - padding: set this to 'same' (default pading is 'valid').\n",
    "        \n",
    "- Define the [MaxPool2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) layer that follows these Conv2D layers. \n",
    "    - Set the following parameters for MaxPool2D:\n",
    "        - pool_size: this will be a tuple with two values.\n",
    "        - strides: this will also be a tuple with two values.\n",
    "\n",
    "### `call`\n",
    "In `call`, you will connect the layers together.\n",
    "- The 0-th conv2D layer, `conv2D_0`, immediately follows the `inputs`.\n",
    "- For conv2D layers 1,2 and onward, you can use a for loop to connect conv2D_1 to conv2D_0, and connect conv2D_2 to conv2D_1, and so on.\n",
    "- After connecting all of the conv2D_i layers, add connect the max_pool layer and return the max_pool layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "WGJGaxVjM00W",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f19295d8925e1d2e60eefd42a6b4dd8",
     "grade": false,
     "grade_id": "cell-1449db9892707876",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "class Block(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
    "        super(Block, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.repetitions = repetitions\n",
    "\n",
    "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
    "        for i in range(repetitions):\n",
    "            \n",
    "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
    "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(filters=self.filters,\n",
    "                                                         kernel_size=self.kernel_size,\n",
    "                                                         activation='relu',\n",
    "                                                         padding='same')\n",
    "        \n",
    "        # Define the max pool layer that will be added after the Conv2D blocks\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=strides)\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        # access the class's conv2D_0 layer\n",
    "        conv2D_0 = vars(self)['conv2D_0']\n",
    "        \n",
    "        # Connect the conv2D_0 layer to inputs\n",
    "        x = conv2D_0(inputs)\n",
    "\n",
    "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
    "        for i in range(1, self.repetitions):\n",
    "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
    "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
    "            \n",
    "            # Use the conv2D_i and connect it to the previous layer\n",
    "            x = conv2D_i(x)\n",
    "\n",
    "        # Finally, add the max_pool layer\n",
    "        max_pool = self.max_pool(x)\n",
    "        \n",
    "        return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xokMgbaSPY3U",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4027611c9615b1f518a95d76a81bc8d1",
     "grade": true,
     "grade_id": "cell-2911e521bce8793b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "a6c2add9-eb11-4862-8d4c-6bba4c920183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils.test_block_class(Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peM2GP6uYT0U"
   },
   "source": [
    "## Create the Custom VGG network (TODO)\n",
    "This model stack has a series of VGG blocks, which can be created using the `Block` class that you defined earlier.\n",
    "\n",
    "### `__init__`\n",
    "- Recall that the `__init__` constructor of `Block` takes several function parameters, \n",
    "    - filters, kernel_size, repetitions: you'll set these.\n",
    "    - kernel_size and strides: you can use the default values.\n",
    "- For blocks a through e, build the blocks according to the following specifications:\n",
    "- block_a: 64  filters, kernel_size 3, repetitions 2\n",
    "- block_b: 128 filters, kernel_size 3, repetitions 2\n",
    "- block_c: 256 filters, kernel_size 3, repetitions 3\n",
    "- block_d: 512 filters, kernel_size 3, repetitions 3\n",
    "- block_e: 512 filters, kernel_size 3, repetitions 3\n",
    "\n",
    "After block 'e', add the following layers:\n",
    "- flatten: use [Flatten](https://keras.io/api/layers/reshaping_layers/flatten/).\n",
    "- fc: create a fully connected layer using [Dense](https://keras.io/api/layers/core_layers/dense/).  Give this 256 units, and a `'relu'` activation.\n",
    "- classifier: create the classifier using a Dense layer.  The number of units equals the number of classes.  For multi-class classification, use a `'softmax'` activation.\n",
    "\n",
    "### `call`\n",
    "Connect these layers together using the functional API syntax:\n",
    "- inputs\n",
    "- block_a\n",
    "- block_b\n",
    "- block_c\n",
    "- block_d\n",
    "- block_e\n",
    "- flatten\n",
    "- fc\n",
    "- classifier\n",
    "\n",
    "Return the classifier layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "yD-paeGiNGvz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "523346a38f53bc31e080114e98e8eca6",
     "grade": false,
     "grade_id": "cell-d9e90af0898eb47f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "class MyVGG(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyVGG, self).__init__()\n",
    "\n",
    "        # Creating blocks of VGG with the following \n",
    "        # (filters, kernel_size, repetitions) configurations\n",
    "        self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\n",
    "        self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\n",
    "        self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\n",
    "        self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\n",
    "        self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\n",
    "\n",
    "        # Classification head\n",
    "        # Define a Flatten layer\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
    "        self.fc = tf.keras.layers.Dense(256, activation='relu')\n",
    "        \n",
    "        # Finally add the softmax classifier using a Dense layer\n",
    "        self.classifier = tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # Chain all the layers one after the other\n",
    "        x = self.block_a(inputs)\n",
    "        x = self.block_b(x)\n",
    "        x = self.block_c(x)\n",
    "        x = self.block_d(x)\n",
    "        x = self.block_e(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zORv4xq4PY3V",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79d77a2aa7ee7f82d707558cf5206868",
     "grade": true,
     "grade_id": "cell-559ac19437f4f2b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "28e5eced-6964-48ec-8f8b-4e3e8d7eca98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils.test_myvgg_class(MyVGG, Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RLR_PJ9PY3V"
   },
   "source": [
    "### Load data and train the VGG network (Optional)\n",
    "You can now load the dataset and proceed to train your VGG network. \n",
    "- This will take a few minutes to complete and is **not required to complete the assignment**.\n",
    "- You can submit your work before starting the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MaF763OKNJxU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 22:56:54.985943: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to data/cats_vs_dogs/4.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9ed95abd7442c482c8987d4738e085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a187ac071249efb9a7e94189a9ecfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling data/cats_vs_dogs/4.0.0.incompleteNSIE4V/cats_vs_dogs-train.tfrecord*...:   0%|          | 0/23262 […"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to data/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Epoch 1/10\n",
      "223/727 [========>.....................] - ETA: 4:27 - loss: 0.6927 - accuracy: 0.5209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/727 [=========>....................] - ETA: 4:08 - loss: 0.6924 - accuracy: 0.5279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/727 [==========>...................] - ETA: 4:01 - loss: 0.6922 - accuracy: 0.5284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/727 [===========>..................] - ETA: 3:38 - loss: 0.6914 - accuracy: 0.5315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/727 [=============>................] - ETA: 3:12 - loss: 0.6906 - accuracy: 0.5317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/727 [==============>...............] - ETA: 3:11 - loss: 0.6906 - accuracy: 0.5320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/727 [==============>...............] - ETA: 3:03 - loss: 0.6904 - accuracy: 0.5344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/727 [=================>............] - ETA: 2:30 - loss: 0.6897 - accuracy: 0.5423"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(preprocess)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the custom VGG model\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mvgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data/')\n",
    "\n",
    "# Initialize VGG with the number of classes \n",
    "vgg = MyVGG(num_classes=2)\n",
    "\n",
    "# Compile with losses and metrics\n",
    "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(features):\n",
    "    # Resize and normalize\n",
    "    image = tf.image.resize(features['image'], (224, 224))\n",
    "    return tf.cast(image, tf.float32) / 255., features['label']\n",
    "\n",
    "# Apply transformations to dataset\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "# Train the custom VGG model\n",
    "vgg.fit(dataset, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ExerciseAnswer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
